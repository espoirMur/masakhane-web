name: "ensemble_model"
max_batch_size: 0
platform: "ensemble"
input[
  {
    name: "TEXT",
    data_type: TYPE_STRING,
    dims: [ -1]
  }
]
output
  {
    name: "last_hidden_state",
    data_type: TYPE_FP32,
    dims: [-1, -1, 1024]
    # -1: mean any batch size, -1: mean any sequence length, 1024: mean 1024 hidden size
  }


ensemble_scheduling {
    step [
        {
            model_name: "tokenizer"
            model_version: -1
            input_map {
                key: "TEXT"
                value: "TEXT"
            }
            output_map [{
                key: "input_ids"
                value: "input_ids"
            },
            {
                key: "attention_mask"
                value: "attention_mask"
            }]},
            {
            model_name: "encoder"
            model_version: -1
            input_map [{
                key: "input_ids"
                value: "input_ids"
            },
            {
                key: "attention_mask"
                value: "attention_mask"
            }]
            output_map {
                key: "last_hidden_state"
                value: "last_hidden_state"
            }
            }
    ]
}
